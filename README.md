从0开始以c++尝试极朴素思路机器学习，闭门造车，暂时不看网课教材
以下是相关思考：
不借助其他参考信息，那么尝试编写人工智能的朴素思路应该是模拟人脑。
我管正在编写的小程序叫“小林”。
----------------------------------------------------------------------------------
我提取了一些简单的模块和步骤，类似程序三环节，接收信息、处理信息、输出信息。
接受信息首先是编码，这里只需要把汉字和英文等进行区分，随后对每一个字进行编码，用整型进行存储。这样一来，机器就可以不考虑其中具体字符内容，而仅仅处理不同id的组合。
编码后的问题是信息以什么形式进行存储，我这里的想法是使用键值对，维护一个字表，每个字有对应的其他每个字的联系表，这就是字与字的联系。我当然知道字与字之间的联系或许并不是简单的一维链接，但目前只想做一个最简单的，因此我仅仅使用距离来衡量一句话中两个字的联系。
----------------------------------------------------------------------------------
目前的进展是逻辑上大致没问题，但到对每个字联系表排序来组词这个步骤的优化中出现了问题，那就是似乎出现了内存泄露。输入1212，其中的排序结果子表中出现了空值。经过排查，map转vector过程中首末长度发生了异常改变。等等，我好像知道了。
我是sb，我在访问的时候没注意边界，让其越界访问，导致给map数组创造了没定义的空间。废了，这个问题改了我两小时，回去又得少打两小时王者。
收工，明天的计划是写注意力机制，如果有时间就准备生成了。
----------------------------------------------------------------------------------
1.13，今天写了注意力，思路是统计字出现的频率，出现最高的就是关键字。但实际上，根据运行结果，全部都是的的的我我我你你你在在在。我想这和婴儿一样，首先也是注意到某个词的频率特别突出，然后就可以先单独学习该词，就像牙牙学语时不断重复的“爸爸妈妈”。小孩子会对爸爸妈妈认错，因此需要不断矫正，这个过程中涉及到对提取的关键字的建模，那么我将再划一块叫做“理解”的区域给他存这些达到建模指标的东西。
![image](https://github.com/user-attachments/assets/3093f24f-7153-425a-8a6f-207c91390763)
----------------------------------------------------------------------------------
理解学习的地方先不写，我再好好想想。先把按字搜索句链的部分写了，现在勉强可以看作是在胡乱说着一些词，而不再是只能说单个词了。
----------------------------------------------------------------------------------
关于学习理解部分，目前有两个思路，一是用其他字词给每个字词定义，二是不学习定义，而是直接记录句子网络。网络显然是非常必要的，然而我担心不进行定义而仅仅学习网络会导致从根本上缺失理论上限。先尝试学习网络。
关于网络，考虑一种结构：网络中的每个点包括父节点、子节点、链接。链接有诸多类型，例如“的地得是”等等，这些可以看作是父子关系的具体形式。等等，所以直接用那些链接就行了，不必引入父子概念。
接下来还有这些问题：如何用算法让其自动认识到链接的类型，以及形成网络之后如何更新迭代？
语句网络应该是环少链长的形态，
之前搜索句链的形式只是基于简单的概率统计，在全局下看控制数据输入可以取得不错的效果，但缺点是单一性，不可能存在语境概念，毕竟在学习的过程中完全没有考虑到上下文的逻辑。
每个字维护一个列表，该列表对每个字包含一个语序列表，列表中的每个数意味着其搜索到该前字以及本字时的前置字数，也就是该链条长度及方向。这种方式在长句上基本不存在意义，因此只能用来记忆理解短句和某些固定搭配。
存储子链、查找子链
似乎之前的思路不够清晰，应该主要分两个方面，一个是增量信息，一个是存量信息。增量，也就是输入的句子，包含什么信息？主要是句子本身的组合。那么如何记录？把句子编码然后记忆，等到需要的时候直接调用输出？也许可行。先试试。
今天分块识别基本完工，具体内容下次再补充吧，先把代码更新了。
---------------------------------------------------------------------------------
喜报喜报，能生成像模像样的句子了，虽然内容单一且僵硬。接下来就是如何正确组织语言和调整。
---------------------------------------------------------------------------------
悲报，以上的所有思路都被前任实践过了，我真的只是在造轮子...我以为大语言模型真的纯粹基于数学模型和概率论知识，没有什么算法的雕琢...但其实我能想到的人家也能想到
![image](https://github.com/user-attachments/assets/0f3d20b6-77db-491b-95d2-411b2f91ef0f)
我还是换一个思路试试看吧。我希望可以强算法而弱数据、弱概率，先尝试吧。

